{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rajeev-gupta/sensyn_ws/src/object_detector/scripts'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os, time\n",
    "import logging\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "workspace_path = os.path.abspath(os.getcwd() + '/../')\n",
    "sys.path.insert(0, workspace_path)\n",
    "workspace_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcdet.models.detectors import GraphRCNN\n",
    "from pcdet.config import cfg, cfg_from_yaml_file\n",
    "from pcdet.utils.calibration_kitti import Calibration\n",
    "from pcdet.utils.common_utils import create_logger\n",
    "from pcdet.datasets.kitti.kitti_utils import calib_to_matricies\n",
    "from pcdet.models import load_data_to_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = './test_logs.txt'\n",
    "# relative paths wrt tools\n",
    "cfg_file  = '/tools/cfgs/kitti_models/graph_rcnn_voi.yaml'\n",
    "ckpt_path = '/tools/ckpts/graph_rcnn_voi_kitti.pth'\n",
    "to_cpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = create_logger(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROOT_DIR': PosixPath('/home/rajeev-gupta/sensyn_ws/src/object_detector/scripts'),\n",
       " 'LOCAL_RANK': 0,\n",
       " 'CLASS_NAMES': ['Car'],\n",
       " 'DATA_CONFIG': {'DATASET': 'KittiDataset',\n",
       "  'DATA_PATH': '../data/kitti',\n",
       "  'BACKEND': {'NAME': 'HardDiskBackend'},\n",
       "  'POINT_CLOUD_RANGE': [0, -40, -3, 70.4, 40, 1],\n",
       "  'DATA_SPLIT': {'train': 'train', 'test': 'test'},\n",
       "  'INFO_PATH': {'train': ['kitti_infos_train.pkl'],\n",
       "   'test': ['kitti_infos_test.pkl']},\n",
       "  'GET_ITEM_LIST': ['points', 'image', 'calib_matricies', 'gt_boxes2d'],\n",
       "  'FOV_POINTS_ONLY': True,\n",
       "  'ENABLE_SIMILAR_TYPE': True,\n",
       "  'DATA_AUGMENTOR': {'DISABLE_AUG_LIST': ['placeholder'],\n",
       "   'AUG_CONFIG_LIST': [{'NAME': 'random_world_flip',\n",
       "     'PROBABILITY': 0.5,\n",
       "     'ALONG_AXIS_LIST': ['x']},\n",
       "    {'NAME': 'random_world_rotation',\n",
       "     'PROBABILITY': 1.0,\n",
       "     'WORLD_ROT_ANGLE': [-0.78539816, 0.78539816]},\n",
       "    {'NAME': 'random_world_scaling',\n",
       "     'PROBABILITY': 1.0,\n",
       "     'WORLD_SCALE_RANGE': [0.95, 1.05]}]},\n",
       "  'POINT_FEATURE_ENCODING': {'encoding_type': 'absolute_coordinates_encoding',\n",
       "   'used_feature_list': ['x', 'y', 'z', 'intensity'],\n",
       "   'src_feature_list': ['x', 'y', 'z', 'intensity']},\n",
       "  'DATA_PROCESSOR': [{'NAME': 'mask_points_and_boxes_outside_range',\n",
       "    'REMOVE_OUTSIDE_BOXES': True},\n",
       "   {'NAME': 'shuffle_points',\n",
       "    'SHUFFLE_ENABLED': {'train': True, 'test': False}},\n",
       "   {'NAME': 'calculate_grid_size', 'VOXEL_SIZE': [0.05, 0.05, 0.1]},\n",
       "   {'NAME': 'imrescale',\n",
       "    'IMAGE_SCALES': {'train': [[640, 192], [2560, 768]],\n",
       "     'test': [[1280, 384]]},\n",
       "    'KEEP_RATIO': True},\n",
       "   {'NAME': 'imflip', 'FLIP_RATIO': {'train': 0.5, 'test': 0}},\n",
       "   {'NAME': 'imnormalize',\n",
       "    'MEAN': [104.014, 114.034, 119.917],\n",
       "    'STD': [73.603, 69.891, 70.915],\n",
       "    'TO_RGB': False},\n",
       "   {'NAME': 'impad', 'SIZE_DIVISOR': 32}],\n",
       "  '_BASE_CONFIG_': 'cfgs/dataset_configs/kitti_dataset.yaml'},\n",
       " 'MODEL': {'NAME': 'GraphRCNN',\n",
       "  'FREEZE_LAYERS': ['DynVFE',\n",
       "   'VoxelBackBone8x',\n",
       "   'HeightCompression',\n",
       "   'BaseBEVBackbone',\n",
       "   'AnchorHeadSingle',\n",
       "   'DLASeg'],\n",
       "  'IMG_BACKBONE': {'NAME': 'DLASeg',\n",
       "   'BASE_NAME': 'dla34',\n",
       "   'DOWN_RATIO': 4,\n",
       "   'LAST_LEVEL': 5},\n",
       "  'VFE': {'NAME': 'DynVFE', 'TYPE': 'mean'},\n",
       "  'BACKBONE_3D': {'NAME': 'VoxelBackBone8x'},\n",
       "  'MAP_TO_BEV': {'NAME': 'HeightCompression', 'NUM_BEV_FEATURES': 256},\n",
       "  'BACKBONE_2D': {'NAME': 'BaseBEVBackbone',\n",
       "   'LAYER_NUMS': [4, 4],\n",
       "   'LAYER_STRIDES': [1, 2],\n",
       "   'NUM_FILTERS': [64, 128],\n",
       "   'UPSAMPLE_STRIDES': [1, 2],\n",
       "   'NUM_UPSAMPLE_FILTERS': [128, 128]},\n",
       "  'DENSE_HEAD': {'NAME': 'AnchorHeadSingle',\n",
       "   'CLASS_AGNOSTIC': False,\n",
       "   'USE_DIRECTION_CLASSIFIER': True,\n",
       "   'DIR_OFFSET': 0.78539,\n",
       "   'DIR_LIMIT_OFFSET': 0.0,\n",
       "   'NUM_DIR_BINS': 2,\n",
       "   'ANCHOR_GENERATOR_CONFIG': [{'class_name': 'Car',\n",
       "     'anchor_sizes': [[3.9, 1.6, 1.56]],\n",
       "     'anchor_rotations': [0, 1.57],\n",
       "     'anchor_bottom_heights': [-1.78],\n",
       "     'align_center': False,\n",
       "     'feature_map_stride': 8,\n",
       "     'matched_threshold': 0.6,\n",
       "     'unmatched_threshold': 0.45}],\n",
       "   'TARGET_ASSIGNER_CONFIG': {'NAME': 'AxisAlignedTargetAssigner',\n",
       "    'POS_FRACTION': -1.0,\n",
       "    'SAMPLE_SIZE': 512,\n",
       "    'NORM_BY_NUM_EXAMPLES': False,\n",
       "    'MATCH_HEIGHT': False,\n",
       "    'BOX_CODER': 'ResidualCoder'},\n",
       "   'LOSS_CONFIG': {'LOSS_WEIGHTS': {'cls_weight': 1.0,\n",
       "     'loc_weight': 2.0,\n",
       "     'dir_weight': 0.2,\n",
       "     'code_weights': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}},\n",
       "  'ROI_HEAD': {'NAME': 'GraphRCNNHead',\n",
       "   'CLASS_AGNOSTIC': True,\n",
       "   'NMS_CONFIG': {'TRAIN': {'NMS_TYPE': 'nms_gpu',\n",
       "     'MULTI_CLASSES_NMS': False,\n",
       "     'NMS_PRE_MAXSIZE': 9000,\n",
       "     'NMS_POST_MAXSIZE': 512,\n",
       "     'NMS_THRESH': 0.8},\n",
       "    'TEST': {'NMS_TYPE': 'nms_gpu',\n",
       "     'MULTI_CLASSES_NMS': False,\n",
       "     'NMS_PRE_MAXSIZE': 2048,\n",
       "     'NMS_POST_MAXSIZE': 100,\n",
       "     'NMS_THRESH': 0.7}},\n",
       "   'DFVS_CONFIG': {'NUM_DVS_POINTS': 2048,\n",
       "    'NUM_FPS_POINTS': 128,\n",
       "    'HASH_SIZE': 4099,\n",
       "    'LAMBDA': 0.12,\n",
       "    'DELTA': 50,\n",
       "    'POOL_EXTRA_WIDTH': [0.5, 0.5, 0.5],\n",
       "    'NUM_BOXES_PER_PATCH': 32},\n",
       "   'IMG_CONFIG': {'IN_DIM': 64, 'MLPS': [32, 32]},\n",
       "   'ATTN_GNN_CONFIG': {'IN_DIM': 42,\n",
       "    'OUT_DIM': 512,\n",
       "    'MLPS': [64, 64, 128],\n",
       "    'CALIB_DIM': 128,\n",
       "    'EXP_MLPS': [128, 512],\n",
       "    'K': 4,\n",
       "    'USE_FEATS_DIS': False,\n",
       "    'USE_REDUCTION': False,\n",
       "    'USE_SHORT_CUT': False},\n",
       "   'TARGET_CONFIG': {'BOX_CODER': 'ResidualCoder',\n",
       "    'ROI_PER_IMAGE': 128,\n",
       "    'FG_RATIO': 0.5,\n",
       "    'SAMPLE_ROI_BY_EACH_CLASS': True,\n",
       "    'CLS_SCORE_TYPE': 'roi_iou',\n",
       "    'CLS_FG_THRESH': 0.75,\n",
       "    'CLS_BG_THRESH': 0.25,\n",
       "    'CLS_BG_THRESH_LO': 0.1,\n",
       "    'HARD_BG_RATIO': 0.8,\n",
       "    'REG_FG_THRESH': 0.55},\n",
       "   'LOSS_CONFIG': {'CLS_LOSS': 'BinaryCrossEntropy',\n",
       "    'REG_LOSS': 'WeightedSmoothL1Loss',\n",
       "    'CORNER_LOSS_REGULARIZATION': True,\n",
       "    'LOSS_WEIGHTS': {'rcnn_cls_weight': 1.0,\n",
       "     'rcnn_reg_weight': 1.0,\n",
       "     'rcnn_corner_weight': 1.0,\n",
       "     'code_weights': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}},\n",
       "  'POST_PROCESSING': {'RECALL_THRESH_LIST': [0.3, 0.5, 0.7],\n",
       "   'SCORE_THRESH': 0.3,\n",
       "   'OUTPUT_RAW_SCORE': False,\n",
       "   'EVAL_METRIC': 'kitti',\n",
       "   'NMS_CONFIG': {'MULTI_CLASSES_NMS': False,\n",
       "    'NMS_TYPE': 'nms_gpu',\n",
       "    'NMS_THRESH': 0.1,\n",
       "    'NMS_PRE_MAXSIZE': 4096,\n",
       "    'NMS_POST_MAXSIZE': 500}}},\n",
       " 'OPTIMIZATION': {'BATCH_SIZE_PER_GPU': 1,\n",
       "  'NUM_EPOCHS': 80,\n",
       "  'OPTIMIZER': 'adam_onecycle',\n",
       "  'LR': 0.003,\n",
       "  'WEIGHT_DECAY': 0.01,\n",
       "  'MOMENTUM': 0.9,\n",
       "  'MOMS': [0.95, 0.85],\n",
       "  'PCT_START': 0.4,\n",
       "  'DIV_FACTOR': 10,\n",
       "  'DECAY_STEP_LIST': [35, 45],\n",
       "  'LR_DECAY': 0.1,\n",
       "  'LR_CLIP': 1e-07,\n",
       "  'LR_WARMUP': False,\n",
       "  'WARMUP_EPOCH': 1,\n",
       "  'GRAD_NORM_CLIP': 10}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_from_yaml_file(workspace_path+cfg_file, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch.utils.data as torch_data\n",
    "\n",
    "from pcdet.datasets.processor.data_processor import DataProcessor\n",
    "from pcdet.datasets.processor.point_feature_encoder import PointFeatureEncoder\n",
    "\n",
    "class CustomKittiDataset(torch_data.Dataset):\n",
    "    def __init__(self, dataset_cfg=None, class_names=None, training=True, root_path=None, logger=None):\n",
    "        super().__init__()\n",
    "        self.dataset_cfg = dataset_cfg\n",
    "        self.training = training\n",
    "        self.class_names = class_names\n",
    "        self.logger = logger\n",
    "        self.root_path = Path(root_path) if root_path is not None else Path(self.dataset_cfg.DATA_PATH)\n",
    "\n",
    "        self.point_cloud_range = np.array(self.dataset_cfg.POINT_CLOUD_RANGE, dtype=np.float32)\n",
    "        self.point_feature_encoder = PointFeatureEncoder(\n",
    "            self.dataset_cfg.POINT_FEATURE_ENCODING,\n",
    "            point_cloud_range=self.point_cloud_range\n",
    "        )\n",
    "        self.data_processor = DataProcessor(\n",
    "            self.dataset_cfg.DATA_PROCESSOR, point_cloud_range=self.point_cloud_range,\n",
    "            training=self.training, num_point_features=self.point_feature_encoder.num_point_features\n",
    "        )\n",
    "        self.grid_size = self.data_processor.grid_size\n",
    "        self.voxel_size = self.data_processor.voxel_size\n",
    "        self.total_epochs = 0\n",
    "        self.cur_epoch = 0\n",
    "        self._merge_all_iters_to_one_epoch = False\n",
    "\n",
    "    @property\n",
    "    def mode(self):\n",
    "        return 'train' if self.training else 'test'\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        info_path = '/media/rajeev-gupta/Drive250/data/kitti/kitti_infos_test.pkl'\n",
    "        with open(info_path, 'rb') as i_file:\n",
    "            i_dict = pickle.load(i_file)\n",
    "        info = i_dict[index]\n",
    "        \n",
    "        sample_idx = info['point_cloud']['lidar_idx']\n",
    "        img_shape = info['image']['image_shape']\n",
    "        calib = self.get_calib(sample_idx)\n",
    "        get_item_list = self.dataset_cfg.get('GET_ITEM_LIST', ['points'])\n",
    "\n",
    "        input_dict = {\n",
    "            'frame_id': sample_idx,\n",
    "            'calib': calib,\n",
    "        }\n",
    "\n",
    "        if \"points\" in get_item_list:\n",
    "            points = self.get_lidar(sample_idx)\n",
    "            if self.dataset_cfg.FOV_POINTS_ONLY:\n",
    "                pts_rect = calib.lidar_to_rect(points[:, 0:3])\n",
    "                fov_flag = self.get_fov_flag(pts_rect, img_shape, calib)\n",
    "                points = points[fov_flag]\n",
    "            input_dict['points'] = points\n",
    "\n",
    "        if \"image\" in get_item_list:\n",
    "            input_dict['image'] = self.get_image(sample_idx)\n",
    "\n",
    "        if \"calib_matricies\" in get_item_list:\n",
    "            input_dict[\"trans_lidar_to_cam\"], input_dict[\"trans_cam_to_img\"] = calib_to_matricies(calib)\n",
    "\n",
    "        data_dict = self.prepare_data(data_dict=input_dict)\n",
    "\n",
    "        data_dict['image_shape'] = img_shape\n",
    "        return data_dict\n",
    "    \n",
    "    def get_calib(self, idx):\n",
    "        calib_file = self.root_path / 'testing' / 'calib' / ('%s.txt' % idx)\n",
    "        return Calibration(calib_file)\n",
    "\n",
    "    def get_lidar(self, idx):\n",
    "        lidar_file = self.root_path / 'testing' / 'velodyne' / ('%s.bin' % idx)\n",
    "        return np.fromfile(lidar_file, dtype=np.float32).reshape(-1, 4)\n",
    "    \n",
    "    def get_image(self, idx):\n",
    "        img_file = self.root_path / 'testing' / 'image_2' / ('%s.png' % idx)\n",
    "        return cv2.imread(str(img_file), cv2.IMREAD_COLOR)\n",
    "    \n",
    "    def prepare_data(self, data_dict):\n",
    "        if data_dict.get('points', None) is not None:\n",
    "            data_dict = self.point_feature_encoder.forward(data_dict)\n",
    "\n",
    "        data_dict = self.data_processor.forward(\n",
    "            data_dict=data_dict\n",
    "        )\n",
    "        return data_dict\n",
    "\n",
    "    @staticmethod\n",
    "    def get_fov_flag(pts_rect, img_shape, calib):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pts_rect:\n",
    "            img_shape:\n",
    "            calib:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        \"\"\"\n",
    "        pts_img, pts_rect_depth = calib.rect_to_img(pts_rect)\n",
    "        val_flag_1 = np.logical_and(pts_img[:, 0] >= 0, pts_img[:, 0] < img_shape[1])\n",
    "        val_flag_2 = np.logical_and(pts_img[:, 1] >= 0, pts_img[:, 1] < img_shape[0])\n",
    "        val_flag_merge = np.logical_and(val_flag_1, val_flag_2)\n",
    "        pts_valid_flag = np.logical_and(val_flag_merge, pts_rect_depth >= 0)\n",
    "\n",
    "        return pts_valid_flag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomKittiDataset(\n",
    "        dataset_cfg=cfg.DATA_CONFIG,\n",
    "        class_names=cfg.CLASS_NAMES,\n",
    "        root_path='/home/rajeev-gupta/sensyn_ws/src/GD-MAE/data/kitti',\n",
    "        training=False,\n",
    "        logger=logger,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17119/2630276673.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphRCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLASS_NAMES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/sensyn_ws/src/object_detector/scripts/pcdet/models/detectors/graph_rcnn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_cfg, num_class, dataset, logger)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_cfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_networks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FREEZE_LAYERS'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFREEZE_LAYERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sensyn_ws/src/object_detector/scripts/pcdet/models/detectors/detector3d_template.py\u001b[0m in \u001b[0;36mbuild_networks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_topology\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             module, model_info_dict = getattr(self, 'build_%s' % module_name)(\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0mmodel_info_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_info_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             )\n\u001b[1;32m     58\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sensyn_ws/src/object_detector/scripts/pcdet/models/detectors/detector3d_template.py\u001b[0m in \u001b[0;36mbuild_dense_head\u001b[0;34m(self, model_info_dict)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mpredict_boxes_when_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ROI_HEAD'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mvoxel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_info_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'voxel_size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0mbackbone_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_info_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'backbone_channels'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         )\n\u001b[1;32m    156\u001b[0m         \u001b[0mmodel_info_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'module_list'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_head_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sensyn_ws/src/object_detector/scripts/pcdet/models/dense_heads/anchor_head_single.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_cfg, input_channels, num_class, class_names, grid_size, point_cloud_range, predict_boxes_when_training, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m         super().__init__(\n\u001b[1;32m     11\u001b[0m             \u001b[0mmodel_cfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrid_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint_cloud_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoint_cloud_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mpredict_boxes_when_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict_boxes_when_training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         )\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sensyn_ws/src/object_detector/scripts/pcdet/models/dense_heads/anchor_head_template.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_cfg, num_class, class_names, grid_size, point_cloud_range, predict_boxes_when_training)\u001b[0m\n\u001b[1;32m     26\u001b[0m         anchors, self.num_anchors_per_location = self.generate_anchors(\n\u001b[1;32m     27\u001b[0m             \u001b[0manchor_generator_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrid_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint_cloud_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoint_cloud_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0manchor_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox_coder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         )\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sensyn_ws/src/object_detector/scripts/pcdet/models/dense_heads/anchor_head_template.py\u001b[0m in \u001b[0;36mgenerate_anchors\u001b[0;34m(anchor_generator_cfg, grid_size, point_cloud_range, anchor_ndim)\u001b[0m\n\u001b[1;32m     41\u001b[0m         )\n\u001b[1;32m     42\u001b[0m         \u001b[0mfeature_map_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgrid_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feature_map_stride'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manchor_generator_cfg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0manchors_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_anchors_per_location_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manchor_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_anchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_map_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0manchor_ndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sensyn_ws/src/object_detector/scripts/pcdet/models/dense_heads/target_assigner/anchor_generator.py\u001b[0m in \u001b[0;36mgenerate_anchors\u001b[0;34m(self, grid_sizes)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             x_shifts = torch.arange(\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchor_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchor_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_stride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             ).cuda()\n\u001b[1;32m     37\u001b[0m             y_shifts = torch.arange(\n",
      "\u001b[0;32m/media/rajeev-gupta/Drive250/conda_envs/new_graphrcnn/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "model = GraphRCNN(cfg.MODEL, num_class=len(cfg.CLASS_NAMES), dataset=dataset, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def get_fov_flag ******************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'frame_id': '000004',\n",
       " 'calib': <pcdet.utils.calibration_kitti.Calibration at 0x7fabbf0d06d0>,\n",
       " 'points': array([[ 3.7786e+01,  7.8970e+00,  1.5140e+00,  9.4000e-01],\n",
       "        [ 3.7753e+01,  8.0140e+00,  1.5140e+00,  9.9000e-01],\n",
       "        [ 3.7741e+01,  8.1360e+00,  1.5150e+00,  9.9000e-01],\n",
       "        ...,\n",
       "        [ 6.3800e+00, -3.2000e-02, -1.6670e+00,  2.2000e-01],\n",
       "        [ 6.3980e+00, -2.2000e-02, -1.6720e+00,  2.1000e-01],\n",
       "        [ 6.3770e+00, -1.0000e-03, -1.6660e+00,  1.2000e-01]],\n",
       "       dtype=float32),\n",
       " 'image': array([[[-1.277312  , -1.5028257 , -1.5781852 ],\n",
       "         [-1.277312  , -1.5028257 , -1.5781852 ],\n",
       "         [-1.2908984 , -1.4599018 , -1.5781852 ],\n",
       "         ...,\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ]],\n",
       " \n",
       "        [[-1.3044848 , -1.4885178 , -1.5781852 ],\n",
       "         [-1.277312  , -1.5028257 , -1.5781852 ],\n",
       "         [-1.277312  , -1.4885178 , -1.5922866 ],\n",
       "         ...,\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ]],\n",
       " \n",
       "        [[-1.3044848 , -1.5028257 , -1.5922866 ],\n",
       "         [-1.277312  , -1.4885178 , -1.5922866 ],\n",
       "         [-1.277312  , -1.4885178 , -1.5922866 ],\n",
       "         ...,\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.38022906,  0.29998145,  0.2831982 ],\n",
       "         [ 0.38022906,  0.29998145,  0.33960375],\n",
       "         [ 0.38022906,  0.34290543,  0.19858986],\n",
       "         ...,\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ]],\n",
       " \n",
       "        [[ 0.28512424,  0.31428945,  0.35370514],\n",
       "         [ 0.27153784,  0.29998145,  0.36780652],\n",
       "         [ 0.27153784,  0.31428945,  0.17038709],\n",
       "         ...,\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ]],\n",
       " \n",
       "        [[ 0.23077863,  0.14259352,  0.07167736],\n",
       "         [ 0.27153784,  0.12828553,  0.04347458],\n",
       "         [ 0.27153784,  0.14259352, -0.08343792],\n",
       "         ...,\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ]]], dtype=float32),\n",
       " 'trans_lidar_to_cam': array([[ 2.3477380e-04, -9.9994415e-01, -1.0563477e-02, -2.7968171e-03],\n",
       "        [ 1.0449408e-02,  1.0565354e-02, -9.9988961e-01, -7.5108789e-02],\n",
       "        [ 9.9994540e-01,  1.2436544e-04,  1.0451303e-02, -2.7213278e-01],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n",
       "       dtype=float32),\n",
       " 'trans_cam_to_img': array([[7.215377e+02, 0.000000e+00, 6.095593e+02, 4.485728e+01],\n",
       "        [0.000000e+00, 7.215377e+02, 1.728540e+02, 2.163791e-01],\n",
       "        [0.000000e+00, 0.000000e+00, 1.000000e+00, 2.745884e-03]],\n",
       "       dtype=float32),\n",
       " 'use_lead_xyz': True,\n",
       " 'transformation_2d_list': ['imrescale'],\n",
       " 'transformation_2d_params': {'imrescale': (1.0241545893719808, 1.024)},\n",
       " 'image_rescale_shape': (384, 1272),\n",
       " 'image_pad_shape': (384, 1280),\n",
       " 'image_shape': array([ 375, 1242], dtype=int32)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dict = dataset.__getitem__(4)\n",
    "get_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_id\n",
      "calib\n",
      "points\n",
      "image\n",
      "trans_lidar_to_cam\n",
      "trans_cam_to_img\n",
      "use_lead_xyz\n",
      "transformation_2d_list\n",
      "transformation_2d_params\n",
      "image_rescale_shape\n",
      "image_pad_shape\n",
      "image_shape\n"
     ]
    }
   ],
   "source": [
    "for key, val in get_dict.items():\n",
    "    print(key)\n",
    "    if type(val) == tuple:\n",
    "        get_dict[key] = list(val)\n",
    "    elif key == 'points':\n",
    "        # add a zero column\n",
    "        n = val.shape[0]\n",
    "        z_col = np.zeros((n, 1), dtype=float)\n",
    "        get_dict[key] = np.concatenate((z_col, val), axis = 1)\n",
    "        continue\n",
    "    elif key == 'image':\n",
    "        # transpose (384, 1280, 3) to (3, 384, 1280)\n",
    "        val_transposed = np.transpose(val, (2, 0, 1))\n",
    "        get_dict[key] = val_transposed\n",
    "        # print(get_dict[key].shape)\n",
    "    elif key == 'transformation_2d_list' or key == 'transformation_2d_params':\n",
    "        get_dict[key] = [val]\n",
    "        continue\n",
    "    get_dict[key] = np.array([get_dict[key]])\n",
    "            \n",
    "get_dict['batch_size'] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frame_id': array(['000004'], dtype='<U6'),\n",
       " 'calib': array([<pcdet.utils.calibration_kitti.Calibration object at 0x7fabbf0d06d0>],\n",
       "       dtype=object),\n",
       " 'points': array([[ 0.00000000e+00,  3.77859993e+01,  7.89699984e+00,\n",
       "          1.51400006e+00,  9.39999998e-01],\n",
       "        [ 0.00000000e+00,  3.77529984e+01,  8.01399994e+00,\n",
       "          1.51400006e+00,  9.90000010e-01],\n",
       "        [ 0.00000000e+00,  3.77410011e+01,  8.13599968e+00,\n",
       "          1.51499999e+00,  9.90000010e-01],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  6.38000011e+00, -3.20000015e-02,\n",
       "         -1.66700006e+00,  2.19999999e-01],\n",
       "        [ 0.00000000e+00,  6.39799976e+00, -2.19999999e-02,\n",
       "         -1.67200005e+00,  2.09999993e-01],\n",
       "        [ 0.00000000e+00,  6.37699986e+00, -1.00000005e-03,\n",
       "         -1.66600001e+00,  1.19999997e-01]]),\n",
       " 'image': array([[[[-1.277312  , -1.277312  , -1.2908984 , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [-1.3044848 , -1.277312  , -1.277312  , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [-1.3044848 , -1.277312  , -1.277312  , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.38022906,  0.38022906,  0.38022906, ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.28512424,  0.27153784,  0.27153784, ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.23077863,  0.27153784,  0.27153784, ...,  0.        ,\n",
       "            0.        ,  0.        ]],\n",
       " \n",
       "         [[-1.5028257 , -1.5028257 , -1.4599018 , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [-1.4885178 , -1.5028257 , -1.4885178 , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [-1.5028257 , -1.4885178 , -1.4885178 , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.29998145,  0.29998145,  0.34290543, ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.31428945,  0.29998145,  0.31428945, ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.14259352,  0.12828553,  0.14259352, ...,  0.        ,\n",
       "            0.        ,  0.        ]],\n",
       " \n",
       "         [[-1.5781852 , -1.5781852 , -1.5781852 , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [-1.5781852 , -1.5781852 , -1.5922866 , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [-1.5922866 , -1.5922866 , -1.5922866 , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.2831982 ,  0.33960375,  0.19858986, ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.35370514,  0.36780652,  0.17038709, ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.07167736,  0.04347458, -0.08343792, ...,  0.        ,\n",
       "            0.        ,  0.        ]]]], dtype=float32),\n",
       " 'trans_lidar_to_cam': array([[[ 2.3477380e-04, -9.9994415e-01, -1.0563477e-02, -2.7968171e-03],\n",
       "         [ 1.0449408e-02,  1.0565354e-02, -9.9988961e-01, -7.5108789e-02],\n",
       "         [ 9.9994540e-01,  1.2436544e-04,  1.0451303e-02, -2.7213278e-01],\n",
       "         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]]],\n",
       "       dtype=float32),\n",
       " 'trans_cam_to_img': array([[[7.215377e+02, 0.000000e+00, 6.095593e+02, 4.485728e+01],\n",
       "         [0.000000e+00, 7.215377e+02, 1.728540e+02, 2.163791e-01],\n",
       "         [0.000000e+00, 0.000000e+00, 1.000000e+00, 2.745884e-03]]],\n",
       "       dtype=float32),\n",
       " 'use_lead_xyz': array([ True]),\n",
       " 'transformation_2d_list': [['imrescale']],\n",
       " 'transformation_2d_params': [{'imrescale': (1.0241545893719808, 1.024)}],\n",
       " 'image_rescale_shape': array([[ 384, 1272]]),\n",
       " 'image_pad_shape': array([[ 384, 1280]]),\n",
       " 'image_shape': array([[ 375, 1242]], dtype=int32),\n",
       " 'batch_size': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 11:33:31,533   INFO  ==> Loading parameters from checkpoint /home/rajeev-gupta/sensyn_ws/src/object_detector/tools/ckpts/graph_rcnn_voi_kitti.pth to GPU\n",
      "2024-07-01 11:33:31,741   INFO  ==> Done (loaded 518/518)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.load_params_from_file(filename=workspace_path+ckpt_path, logger=logger, to_cpu=to_cpu)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Time:  1.7700154781341553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'pred_boxes': tensor([[37.7702, 15.6945, -0.3820,  4.1328,  1.7591,  1.4666,  3.1287]],\n",
       "         device='cuda:0', grad_fn=<IndexBackward0>),\n",
       "  'pred_scores': tensor([0.9051], device='cuda:0', grad_fn=<IndexBackward0>),\n",
       "  'pred_labels': tensor([1], device='cuda:0')}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_input = get_dict\n",
    "# data_input = b_dict\n",
    "torch.cuda.synchronize()\n",
    "start_time = time.time()\n",
    "load_data_to_gpu(data_input)\n",
    "pred_dicts, ret_dict = model(data_input)\n",
    "torch.cuda.synchronize()\n",
    "end_time = time.time()\n",
    "print('Inference Time: ', end_time-start_time)\n",
    "\n",
    "pred_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_path = '/media/rajeev-gupta/Drive250/data/kitti/kitti_infos_test.pkl'\n",
    "with open(info_path, 'rb') as i_file:\n",
    "    i_dict = pickle.load(i_file)\n",
    "len(i_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'point_cloud': {'num_features': 4, 'lidar_idx': '000000'},\n",
       " 'image': {'image_idx': '000000',\n",
       "  'image_shape': array([ 375, 1242], dtype=int32)},\n",
       " 'calib': {'P2': array([[7.21537720e+02, 0.00000000e+00, 6.09559326e+02, 4.48572807e+01],\n",
       "         [0.00000000e+00, 7.21537720e+02, 1.72854004e+02, 2.16379106e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 2.74588400e-03],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00]]),\n",
       "  'R0_rect': array([[ 0.9999239 ,  0.00983776, -0.00744505,  0.        ],\n",
       "         [-0.0098698 ,  0.9999421 , -0.00427846,  0.        ],\n",
       "         [ 0.00740253,  0.00435161,  0.9999631 ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  1.        ]],\n",
       "        dtype=float32),\n",
       "  'Tr_velo_to_cam': array([[ 7.53374491e-03, -9.99971390e-01, -6.16602018e-04,\n",
       "          -4.06976603e-03],\n",
       "         [ 1.48024904e-02,  7.28073297e-04, -9.99890208e-01,\n",
       "          -7.63161778e-02],\n",
       "         [ 9.99862075e-01,  7.52379000e-03,  1.48075502e-02,\n",
       "          -2.71780610e-01],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           1.00000000e+00]])}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_dict[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
