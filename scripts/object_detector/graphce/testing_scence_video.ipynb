{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg_path = '/media/rajeev-gupta/Drive250/SENSYN_/from_sensyn_ws_src/GraphRCNN'\n",
    "sys.path.insert(0, pkg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from det3d import torchie\n",
    "from det3d.torchie import Config\n",
    "from det3d.datasets import build_dataset, build_dataloader\n",
    "from det3d.models import build_detector\n",
    "from det3d.torchie.apis import (\n",
    "    get_root_logger,\n",
    "    batch_processor\n",
    ")\n",
    "from det3d.torchie.trainer import get_dist_info, load_checkpoint\n",
    "from det3d.torchie.trainer.utils import all_gather, synchronize\n",
    "import pickle \n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = 'configs/waymo/voxelnet/two_stage/waymo_centerpoint_voxelnet_graphrcnn_6epoch_freeze_copy.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config.fromfile(cfg_path)\n",
    "cfg.local_rank = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***************************model is build_from_cfg***************************\n",
      "obj_type is str:  TwoStageDetector\n",
      "[In build_from_cfg] building  <class 'det3d.models.detectors.two_stage.TwoStageDetector'>\n",
      "\n",
      "***************************model is build_from_cfg***************************\n",
      "obj_type is str:  VoxelNet\n",
      "[In build_from_cfg] building  <class 'det3d.models.detectors.voxelnet.VoxelNet'>\n",
      "Running super of VoxelNet (SingleStageDetector)\n",
      "\n",
      "***************************model is build_from_cfg***************************\n",
      "obj_type is str:  DynamicVoxelEncoder\n",
      "[In build_from_cfg] building  <class 'det3d.models.readers.dynamic_voxel_encoder.DynamicVoxelEncoder'>\n",
      "\n",
      "***************************model is build_from_cfg***************************\n",
      "obj_type is str:  SpMiddleResNetFHD\n",
      "[In build_from_cfg] building  <class 'det3d.models.backbones.scn.SpMiddleResNetFHD'>\n",
      "\n",
      "***************************model is build_from_cfg***************************\n",
      "obj_type is str:  RPN\n",
      "[In build_from_cfg] building  <class 'det3d.models.necks.rpn.RPN'>\n",
      "\n",
      "***************************model is build_from_cfg***************************\n",
      "obj_type is str:  CenterHead\n",
      "[In build_from_cfg] building  <class 'det3d.models.bbox_heads.center_head.CenterHead'>\n",
      "Use HM Bias:  -2.19\n",
      "load_checkpoint\n",
      "model loaded using LSD\n",
      "model loaded with state dict\n",
      "Init weight from /media/rajeev-gupta/Drive250/SENSYN_/from_sensyn_ws_src/Honghui_weights/centerpoint_epoch_36.pth\n",
      "Freeze First Stage Network\n",
      "\n",
      "***************************model is build_from_cfg***************************\n",
      "obj_type is str:  GraphRCNNHead\n",
      "[In build_from_cfg] building  <class 'det3d.models.roi_heads.roi_head.GraphRCNNHead'>\n"
     ]
    }
   ],
   "source": [
    "model = build_detector(cfg.model, train_cfg=None, test_cfg=cfg.test_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "map_location = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    map_location = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_checkpoint\n",
      "model loaded using LSD\n",
      "model loaded with state dict\n"
     ]
    }
   ],
   "source": [
    "ckpt = load_checkpoint(model, cfg.load_from, map_location, strict=False, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "model.eval()\n",
    "mode = \"val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj_type is str:  WaymoDataset\n",
      "[In build_from_cfg] building  <class 'det3d.datasets.waymo.waymo.WaymoDataset'>\n",
      "Using 1 sweeps\n",
      "Using 1 Frames\n",
      "obj_type is str:  LoadPointCloudFromFile\n",
      "[In build_from_cfg] building  <class 'det3d.datasets.pipelines.loading.LoadPointCloudFromFile'>\n",
      "obj_type is str:  LoadPointCloudAnnotations\n",
      "[In build_from_cfg] building  <class 'det3d.datasets.pipelines.loading.LoadPointCloudAnnotations'>\n",
      "obj_type is str:  Preprocess\n",
      "[In build_from_cfg] building  <class 'det3d.datasets.pipelines.preprocess.Preprocess'>\n",
      "obj_type is str:  AssignLabel\n",
      "[In build_from_cfg] building  <class 'det3d.datasets.pipelines.preprocess.AssignLabel'>\n",
      "obj_type is str:  Reformat\n",
      "[In build_from_cfg] building  <class 'det3d.datasets.pipelines.formating.Reformat'>\n"
     ]
    }
   ],
   "source": [
    "dataset = build_dataset(cfg.data.val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import calibration_waymo\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calib_object(calib_path):\n",
    "    calib = calibration_waymo.get_calib_from_file(calib_path)\n",
    "    calib = calibration_waymo.Calibration(calib)\n",
    "    return calib\n",
    "# get_calib_object(calib_path)\n",
    "def get_image(image_path):\n",
    "    image = cv2.imread(image_path, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "    return image\n",
    "# get_image(image_path)\n",
    "def get_lidar(lidar_path):\n",
    "    lidar = np.fromfile(lidar_path, dtype=np.float32).reshape(-1, 5)\n",
    "    lidar[:, 3] = np.tanh(lidar[:, 3])\n",
    "    return lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image):\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxes3d_lidar_to_kitti_camera(boxes3d_lidar, calib):\n",
    "    \"\"\"\n",
    "    :param boxes3d_lidar: (N, 7) [x, y, z, dx, dy, dz, heading], (x, y, z) is the box center\n",
    "    :param calib:\n",
    "    :return:\n",
    "        boxes3d_camera: (N, 7) [x, y, z, l, h, w, r] in rect camera coords\n",
    "    \"\"\"\n",
    "    import copy\n",
    "    boxes3d_lidar_copy = copy.deepcopy(boxes3d_lidar)\n",
    "    xyz_lidar = boxes3d_lidar_copy[:, 0:3]\n",
    "    l, w, h = boxes3d_lidar_copy[:, 3:4], boxes3d_lidar_copy[:, 4:5], boxes3d_lidar_copy[:, 5:6]\n",
    "    r = boxes3d_lidar_copy[:, 6:7]\n",
    "\n",
    "    xyz_lidar[:, 2] -= h.reshape(-1) / 2\n",
    "    xyz_cam = calib.lidar_to_rect(xyz_lidar)\n",
    "    # xyz_cam[:, 1] += h.reshape(-1) / 2\n",
    "    r = -r - np.pi / 2\n",
    "    return np.concatenate([xyz_cam, l, h, w, r], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/media/rajeev-gupta/Drive250/SENSYN_/from_sensyn_ws_src/GraphRCNN/Ventoy/waymo_data/data/waymo/kitti/raw_data/'\n",
    "segment_folders = ['segment-12974838039736660070_4586_990_4606_990_with_camera_label',\n",
    "                     'segment-13145971249179441231_1640_000_1660_000_with_camera_label',\n",
    "                     'segment-13182548552824592684_4160_250_4180_250_with_camera_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(image, pred_boxes_cam, cam_to_img):\n",
    "    import copy\n",
    "    image_with_boxes = copy.deepcopy(image)\n",
    "    scope_h, scope_k = image.shape[:2]\n",
    "    # print('image_scope: ', scope_h, scope_k)\n",
    "    for line in pred_boxes_cam[:]:\n",
    "    # for line in [pred_boxes_cam[3]]:\n",
    "        dims   = np.asarray([float(number) for number in line[3:6]])\n",
    "        ## swap x, y, only required when reading from GD-MAE test - txt results\n",
    "        tmp = dims[1]\n",
    "        dims[1]=dims[0]\n",
    "        dims[0]=tmp\n",
    "        center = np.asarray([float(number) for number in line[0:3]])\n",
    "        rot_y  = float(line[3]) + np.arctan(center[0]/center[2])\n",
    "        rot_y  = float(line[3]) + float(line[6]) + np.arctan(center[0]/center[2])\n",
    "        rot_y = float(line[6]) + 1.57\n",
    "        # rot_y = 0\n",
    "        box_3d = []\n",
    "        is_bbox_inside_image_scope = True\n",
    "        for i in [1,-1]:\n",
    "            for j in [1,-1]:\n",
    "                for k in [0,1]:\n",
    "                    point = np.copy(center)\n",
    "                    point[0] = center[0] + i * dims[1]/2 * np.cos(-rot_y+np.pi/2) + (j*i) * dims[2]/2 * np.cos(-rot_y)\n",
    "                    point[2] = center[2] + i * dims[1]/2 * np.sin(-rot_y+np.pi/2) + (j*i) * dims[2]/2 * np.sin(-rot_y)                  \n",
    "                    point[1] = center[1] - k * dims[0]\n",
    "                    point = np.append(point, 1)\n",
    "                    point = np.dot(cam_to_img, point)\n",
    "                    point = point[:2]/point[2]\n",
    "                    point = point.astype(np.int16)\n",
    "                    # if point[0]>=scope_h or point[1]>=scope_k or point[0]<0 or point[1]<0:\n",
    "                    if point[0]<0 or point[1]<0:\n",
    "                        is_bbox_inside_image_scope = False\n",
    "                    box_3d.append(point)\n",
    "        if not is_bbox_inside_image_scope:\n",
    "            continue\n",
    "        for i in range(4):\n",
    "            point_1_ = box_3d[2*i]\n",
    "            point_2_ = box_3d[2*i+1]\n",
    "            cv2.line(image_with_boxes, (point_1_[0], point_1_[1]), (point_2_[0], point_2_[1]), (0,255,0), 2)\n",
    "        for i in range(8):\n",
    "            point_1_ = box_3d[i]\n",
    "            point_2_ = box_3d[(i+2)%8]\n",
    "            cv2.line(image_with_boxes, (point_1_[0], point_1_[1]), (point_2_[0], point_2_[1]), (0,255,0), 2)\n",
    "    return image_with_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waymo_GraphCE_0.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/rajeev-gupta/Drive250/conda_envs/new_graphrcnn/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180589158/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n",
      "average time:  0.14837887457438878\n",
      "waymo_GraphCE_1.avi\n",
      "196\n",
      "average time:  0.1421962064139697\n",
      "waymo_GraphCE_2.avi\n",
      "196\n",
      "average time:  0.14630710713717401\n"
     ]
    }
   ],
   "source": [
    "for seg_id, segment in enumerate(segment_folders):\n",
    "    num_frames = 196\n",
    "    video_out = 'waymo_GraphCE_' + str(seg_id) + '.avi'\n",
    "    print(video_out)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    video_writer = cv2.VideoWriter(video_out, fourcc, 25.0, (1920, 1280))\n",
    "\n",
    "    total_time = 0\n",
    "    images_processed = []\n",
    "    for index in range(num_frames):\n",
    "        calib_path = os.path.join(data_path , segment, 'calib', f'{index:06d}.txt')\n",
    "        image_path = os.path.join(data_path , segment, 'image/FRONT', f'{index:06d}.png')\n",
    "        lidar_path = os.path.join(data_path, segment, 'velodyne', f'{index:06d}.bin')\n",
    "        points = get_lidar(lidar_path)\n",
    "        d0 = dataset.__getitem__(0, points)\n",
    "        d0['metadata'] = {'image_prefix': '', 'num_point_features': 5, 'token': ''}\n",
    "        d0['points'] = [torch.Tensor(d0['points'])]\n",
    "        d0['metadata'] = [d0['metadata']]\n",
    "\n",
    "        start_time = time.time()\n",
    "        outputs = batch_processor(\n",
    "                    model, d0, train_mode=False, local_rank=cfg.local_rank,\n",
    "                )\n",
    "        torch.cuda.synchronize()\n",
    "        end_time = time.time()\n",
    "        total_time += end_time-start_time\n",
    "        # print('elapsed time in one batch: ', end_time-start_time)\n",
    "\n",
    "        calib = get_calib_object(calib_path)\n",
    "        cam_to_img = calib.P2\n",
    "\n",
    "        pred_boxes = outputs[0]['box3d_lidar'].cpu().detach().numpy()\n",
    "        # scores = outputs[0]['scores'].cpu().detach().numpy()\n",
    "        # labels = outputs[0]['label_preds'].cpu().detach().numpy()\n",
    "        try:\n",
    "            image = get_image(image_path)\n",
    "        except:\n",
    "            print('couldn\\'t load image')\n",
    "        del outputs\n",
    "\n",
    "        pred_boxes_cam = boxes3d_lidar_to_kitti_camera(pred_boxes, calib)\n",
    "        image_with_boxes = draw_boxes(image, pred_boxes_cam, cam_to_img)\n",
    "        # display_image(image_with_boxes / 255)\n",
    "        # break\n",
    "        images_processed.append(image_with_boxes)\n",
    "    # break\n",
    "    print(len(images_processed))\n",
    "    for image_with_boxes in images_processed:\n",
    "        pause_duration = 0.1\n",
    "        fps = 25\n",
    "        pause_frames = int(pause_duration * fps)\n",
    "        for _ in range(pause_frames):\n",
    "            video_writer.write(np.uint8(image_with_boxes))\n",
    "    del images_processed\n",
    "    # video_writer.release()\n",
    "    \n",
    "    print('average time: ', total_time/num_frames)\n",
    "    time.sleep(4)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ckpt\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 0 starting\n",
      "Thread 1 starting\n",
      "Thread 2 starting\n",
      "Thread 3 starting\n",
      "Thread 4 starting\n",
      "Thread 0 finished\n",
      "Thread 2 finished\n",
      "Thread 4 finished\n",
      "Thread 3 finished\n",
      "Thread 1 finished\n",
      "All threads completed\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def worker(name):\n",
    "    print(f\"Thread {name} starting\")\n",
    "    time.sleep(2)\n",
    "    print(f\"Thread {name} finished\")\n",
    "\n",
    "# Create and start threads\n",
    "threads = []\n",
    "for i in range(5):\n",
    "    t = threading.Thread(target=worker, args=(i,))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "# Wait for all threads to complete\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(\"All threads completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 0 starting\n",
      "Process 1 starting\n",
      "Process 2 starting\n",
      "Process 3 starting\n",
      "Process 4 starting\n",
      "Process 0 finished\n",
      "Process 1 finished\n",
      "Process 2 finished\n",
      "Process 3 finished\n",
      "Process 4 finished\n",
      "All processes completed\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def worker(name):\n",
    "    print(f\"Process {name} starting\")\n",
    "    time.sleep(2)\n",
    "    print(f\"Process {name} finished\")\n",
    "\n",
    "# Create and start processes\n",
    "processes = []\n",
    "for i in range(5):\n",
    "    p = multiprocessing.Process(target=worker, args=(i,))\n",
    "    processes.append(p)\n",
    "    p.start()\n",
    "\n",
    "# Wait for all processes to complete\n",
    "for p in processes:\n",
    "    p.join()\n",
    "\n",
    "print(\"All processes completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "pc = None\n",
    "if pc is not None:\n",
    "    print('not')\n",
    "else:\n",
    "    print('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_graphrcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
